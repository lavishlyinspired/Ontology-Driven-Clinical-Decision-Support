# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# Alternative models you can use:
# OLLAMA_MODEL=mistral:latest
# OLLAMA_MODEL=mixtral:latest
# OLLAMA_MODEL=phi3:latest

# Ontology Paths (all paths relative to project root or absolute)
SNOMED_CT_PATH=H:\akash\git\CoherencePLM\Version22\data\lca_ontologies\snomed_ct\build_snonmed_owl\snomed_ct_optimized.owl
LOINC_PATH=H:\akash\git\CoherencePLM\Version22\data\lca_ontologies\loinc\Loinc_2.81
RXNORM_PATH=H:\akash\git\CoherencePLM\Version22\data\lca_ontologies\rxnorm\RxNorm_full_01052026
LUCADA_ONTOLOGY_OUTPUT=H:\akash\git\CoherencePLM\Version22\data\lca_ontologies\lucada
LUCADA_OWL_FILE=lucada_ontology.owl

# Neo4j Configuration (Required for graph DB and vector embeddings)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=lucada

# MCP Server Configuration
MCP_SERVER_PORT=3000
MCP_SERVER_HOST=localhost

# Vector Store (Neo4j-based)
NEO4J_VECTOR_INDEX=clinical_guidelines_vector

# Logging
LOG_LEVEL=INFO
