# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:latest

# Alternative models you can use:
# OLLAMA_MODEL=mistral:latest
# OLLAMA_MODEL=mixtral:latest
# OLLAMA_MODEL=phi3:latest

# Ontology Paths (relative to project root)
SNOMED_CT_PATH=data/lca_ontologies/snomed_ct/build_snonmed_owl/snomed_ct_optimized.owl
LOINC_PATH=data/lca_ontologies/loinc/Loinc_2.81
RXNORM_PATH=data/lca_ontologies/rxnorm/RxNorm_full_01052026
LUCADA_ONTOLOGY_OUTPUT=data/lca_ontologies/lucada
LUCADA_OWL_FILE=lucada_ontology.owl

# Neo4j Configuration (Required for graph DB and vector embeddings)
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=lucada

# MCP Server Configuration
MCP_SERVER_PORT=3000
MCP_SERVER_HOST=localhost

# Vector Store (Neo4j-based)
NEO4J_VECTOR_INDEX=clinical_guidelines_vector

# Logging Configuration
LOG_LEVEL=INFO
LOG_FORMAT=colored
# Options: colored (console), json (files in production)
LOG_ENABLE_FILE=true
LOG_ENABLE_JSON=false

# LangSmith Tracing (LangChain/LangGraph Observability)
# Sign up at https://smith.langchain.com to get an API key
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=LungCancerAssistant
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
# Enable verbose LangChain debug output
LANGCHAIN_DEBUG=false
