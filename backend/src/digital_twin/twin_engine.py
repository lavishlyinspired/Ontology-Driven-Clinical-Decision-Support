"""
Digital Twin Engine - Core Orchestrator

This is the central "brain" of the Living Digital Twin system.
It manages the patient's digital twin lifecycle, coordinates all agents,
maintains the context graph, and provides real-time updates.

Architecture (from digitaltwin.md):
    Digital Twin Engine
    â”œâ”€â”€ Context Graph Layer (memory)
    â”œâ”€â”€ Agent Orchestration (intelligence)
    â”œâ”€â”€ Specialized Intelligence (agents)
    â””â”€â”€ Knowledge Foundation (ontologies)
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional, Set
from datetime import datetime, timedelta
from dataclasses import dataclass, field
from enum import Enum
import uuid

from ..agents.dynamic_orchestrator import (
    DynamicWorkflowOrchestrator,
    DynamicContextGraph,
    ContextNode,
    ContextEdge,
    WorkflowComplexity
)
from ..agents.biomarker_agent import BiomarkerAgent
from ..agents.nsclc_agent import NSCLCAgent
from ..agents.sclc_agent import SCLCAgent
from ..agents.comorbidity_agent import ComorbidityAgent
from ..db.temporal_analyzer import TemporalAnalyzer
from ..db.neo4j_schema import LUCADAGraphDB

logger = logging.getLogger(__name__)


class TwinState(Enum):
    """Digital twin lifecycle states"""
    INITIALIZING = "initializing"
    ACTIVE = "active"
    MONITORING = "monitoring"
    UPDATING = "updating"
    PREDICTING = "predicting"
    ALERTING = "alerting"
    DORMANT = "dormant"


class UpdateType(Enum):
    """Types of updates to the twin"""
    LAB_RESULT = "lab_result"
    IMAGING = "imaging"
    TREATMENT_CHANGE = "treatment_change"
    PROGRESSION_EVENT = "progression_event"
    BIOMARKER_UPDATE = "biomarker_update"
    CLINICAL_NOTE = "clinical_note"
    ADVERSE_EVENT = "adverse_event"


@dataclass
class TwinAlert:
    """Alert generated by the digital twin"""
    alert_id: str
    severity: str  # "critical", "high", "medium", "low"
    category: str  # "progression", "safety", "intervention_window", "trial_opportunity"
    message: str
    timestamp: datetime
    triggering_event: Optional[str] = None
    recommended_actions: List[str] = field(default_factory=list)
    confidence: float = 0.0
    requires_human_review: bool = False


@dataclass
class TwinSnapshot:
    """Point-in-time snapshot of twin state"""
    snapshot_id: str
    patient_id: str
    timestamp: datetime
    clinical_state: Dict[str, Any]
    predictions: Dict[str, Any]
    active_alerts: List[TwinAlert]
    confidence_scores: Dict[str, float]
    context_graph_summary: Dict[str, Any]


class DigitalTwinEngine:
    """
    Core Digital Twin Engine
    
    Manages the complete lifecycle of a patient's digital twin:
    1. Initialization from patient data
    2. Continuous monitoring and updates
    3. Context graph maintenance
    4. Multi-agent coordination
    5. Prediction and alerting
    6. Intervention window detection
    7. State persistence and recovery
    
    Example:
        twin = DigitalTwinEngine(patient_id="P12345")
        await twin.initialize(patient_data)
        
        # Update with new lab result
        await twin.update({
            "type": "lab_result",
            "test": "EGFR mutation",
            "result": "T790M detected"
        })
        
        # Get current state
        state = twin.get_current_state()
        
        # Get predictions
        predictions = await twin.predict_trajectories()
    """
    
    def __init__(self, patient_id: str, 
                 neo4j_uri: str = None,
                 neo4j_user: str = None,
                 neo4j_password: str = None):
        """
        Initialize Digital Twin Engine for a patient
        
        Args:
            patient_id: Unique patient identifier
            neo4j_uri: Neo4j connection URI
            neo4j_user: Neo4j username
            neo4j_password: Neo4j password
        """
        self.patient_id = patient_id
        self.twin_id = f"twin_{patient_id}_{uuid.uuid4().hex[:8]}"
        self.state = TwinState.INITIALIZING
        self.created_at = datetime.now()
        self.last_updated = datetime.now()
        
        # Core components
        self.context_graph = DynamicContextGraph()
        self.orchestrator = DynamicWorkflowOrchestrator()
        self.temporal_analyzer = TemporalAnalyzer(
            uri=neo4j_uri,
            user=neo4j_user,
            password=neo4j_password
        )
        self.graph_db = LUCADAGraphDB(
            uri=neo4j_uri,
            user=neo4j_user,
            password=neo4j_password
        )
        
        # Specialized agents
        self.agents = {
            "biomarker": BiomarkerAgent(),
            "nsclc": NSCLCAgent(),
            "sclc": SCLCAgent(),
            "comorbidity": ComorbidityAgent()
        }
        
        # Twin memory
        self.patient_data: Dict[str, Any] = {}
        self.active_alerts: List[TwinAlert] = []
        self.prediction_cache: Dict[str, Any] = {}
        self.snapshots: List[TwinSnapshot] = []
        
        # Monitoring configuration
        self.monitoring_enabled = False
        self.monitoring_interval_hours = 24
        self.alert_thresholds = {
            "progression_velocity": 0.15,  # mm/day increase
            "biomarker_change": 0.20,      # 20% allele frequency change
            "confidence_drop": 0.70         # Alert if confidence < 0.70
        }
        
        logger.info(f"âœ“ Digital Twin Engine initialized: {self.twin_id} for patient {patient_id}")
        
    async def initialize(self, patient_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Initialize the digital twin with patient data
        
        This creates the initial context graph, runs baseline analysis,
        and sets up monitoring.
        
        Args:
            patient_data: Complete patient clinical data
            
        Returns:
            Initialization summary with baseline assessments
        """
        logger.info(f"ðŸš€ Initializing digital twin for {self.patient_id}")
        
        self.state = TwinState.INITIALIZING
        self.patient_data = patient_data
        
        # Step 1: Create root patient node in context graph
        patient_node = ContextNode(
            node_id=f"patient_{self.patient_id}",
            node_type="patient",
            content=patient_data,
            confidence=1.0,
            source_agent="twin_engine"
        )
        self.context_graph.add_node(patient_node)
        
        # Step 2: Run initial agent analysis
        agent_registry = {
            "BiomarkerAgent": self.agents["biomarker"].execute,
            "NSCLCAgent": self.agents["nsclc"].execute if patient_data.get("cancer_type") == "NSCLC" else None,
            "SCLCAgent": self.agents["sclc"].execute if patient_data.get("cancer_type") == "SCLC" else None,
            "ComorbidityAgent": self.agents["comorbidity"].execute
        }
        
        # Filter out None agents
        agent_registry = {k: v for k, v in agent_registry.items() if v is not None}
        
        # Run orchestrated workflow
        baseline_result = await self.orchestrator.orchestrate_adaptive_workflow(
            patient_data=patient_data,
            agent_registry=agent_registry
        )
        
        # Step 3: Store results in context graph
        for agent_name, execution in baseline_result.get("agent_results", {}).items():
            if execution.output:
                result_node = ContextNode(
                    node_id=f"baseline_{agent_name}_{uuid.uuid4().hex[:8]}",
                    node_type="agent_output",
                    content=execution.output,
                    confidence=execution.confidence,
                    source_agent=agent_name
                )
                self.context_graph.add_node(result_node)
                
                # Link to patient
                self.context_graph.add_edge(ContextEdge(
                    source_id=patient_node.node_id,
                    target_id=result_node.node_id,
                    relation_type="analyzed_by"
                ))
        
        # Step 4: Persist to Neo4j
        if self.graph_db.is_available:
            try:
                self.graph_db.create_patient_fact(patient_data)
                logger.info("âœ“ Patient data persisted to Neo4j")
            except Exception as e:
                logger.warning(f"âš  Neo4j persistence failed: {e}")
        
        # Step 5: Create initial snapshot
        snapshot = self._create_snapshot(
            clinical_state=patient_data,
            predictions={},
            alerts=[]
        )
        self.snapshots.append(snapshot)
        
        # Step 6: Activate twin
        self.state = TwinState.ACTIVE
        self.last_updated = datetime.now()
        
        logger.info(f"âœ… Digital twin initialized successfully: {self.twin_id}")
        
        return {
            "twin_id": self.twin_id,
            "patient_id": self.patient_id,
            "state": self.state.value,
            "initialized_at": self.created_at.isoformat(),
            "baseline_analysis": baseline_result,
            "context_graph_nodes": len(self.context_graph.nodes),
            "context_graph_edges": len(self.context_graph.edges)
        }
        
    async def update(self, update_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Update the digital twin with new clinical information
        
        This triggers cascading updates through the context graph:
        1. Add new information as context nodes
        2. Detect changes and progression
        3. Re-run affected agents
        4. Update predictions
        5. Generate alerts if needed
        
        Args:
            update_data: {
                "type": UpdateType,
                "data": {...},
                "timestamp": datetime (optional)
            }
            
        Returns:
            Update summary with any generated alerts
        """
        logger.info(f"ðŸ”„ Updating digital twin: {update_data.get('type')}")
        
        self.state = TwinState.UPDATING
        update_type = update_data.get("type")
        data = update_data.get("data", {})
        timestamp = update_data.get("timestamp", datetime.now())
        
        # Step 1: Create update node in context graph
        update_node = ContextNode(
            node_id=f"update_{update_type}_{uuid.uuid4().hex[:8]}",
            node_type="event",
            content=data,
            timestamp=timestamp,
            source_agent="twin_engine",
            tags={update_type, "update"}
        )
        self.context_graph.add_node(update_node)
        
        # Link to patient
        patient_node_id = f"patient_{self.patient_id}"
        if patient_node_id in self.context_graph.nodes:
            self.context_graph.add_edge(ContextEdge(
                source_id=patient_node_id,
                target_id=update_node.node_id,
                relation_type="received_update"
            ))
        
        # Step 2: Detect what changed
        changes_detected = self._detect_changes(update_type, data)
        
        # Step 3: Re-run affected agents
        affected_agents = self._identify_affected_agents(update_type, changes_detected)
        
        agent_results = {}
        for agent_name in affected_agents:
            if agent_name in self.agents:
                try:
                    # Merge update data with existing patient data
                    updated_patient_data = {**self.patient_data, **data}
                    
                    result = self.agents[agent_name].execute(updated_patient_data)
                    agent_results[agent_name] = result
                    
                    # Add result to context graph
                    result_node = ContextNode(
                        node_id=f"result_{agent_name}_{uuid.uuid4().hex[:8]}",
                        node_type="agent_output",
                        content=result,
                        source_agent=agent_name
                    )
                    self.context_graph.add_node(result_node)
                    
                    # Link update â†’ agent result
                    self.context_graph.add_edge(ContextEdge(
                        source_id=update_node.node_id,
                        target_id=result_node.node_id,
                        relation_type="triggered"
                    ))
                    
                except Exception as e:
                    logger.error(f"âš  Agent {agent_name} failed: {e}")
        
        # Step 4: Update predictions if needed
        new_predictions = {}
        if self._should_update_predictions(update_type, changes_detected):
            new_predictions = await self.predict_trajectories()
        
        # Step 5: Generate alerts
        new_alerts = self._generate_alerts(
            update_type=update_type,
            changes=changes_detected,
            agent_results=agent_results,
            predictions=new_predictions
        )
        
        self.active_alerts.extend(new_alerts)
        
        # Step 6: Update patient data
        self.patient_data.update(data)
        self.last_updated = datetime.now()
        self.state = TwinState.ACTIVE
        
        # Step 7: Create snapshot
        snapshot = self._create_snapshot(
            clinical_state=self.patient_data,
            predictions=new_predictions,
            alerts=new_alerts
        )
        self.snapshots.append(snapshot)
        
        logger.info(f"âœ… Twin updated: {len(new_alerts)} new alerts, {len(affected_agents)} agents re-run")
        
        return {
            "twin_id": self.twin_id,
            "update_type": update_type,
            "updated_at": self.last_updated.isoformat(),
            "changes_detected": changes_detected,
            "affected_agents": affected_agents,
            "agent_results": agent_results,
            "new_predictions": new_predictions,
            "new_alerts": [
                {
                    "severity": alert.severity,
                    "category": alert.category,
                    "message": alert.message,
                    "confidence": alert.confidence
                }
                for alert in new_alerts
            ],
            "total_active_alerts": len(self.active_alerts)
        }
        
    async def predict_trajectories(self) -> Dict[str, Any]:
        """
        Predict likely disease trajectories
        
        Uses temporal analysis and similar patient patterns
        
        Returns:
            {
                "pathways": List[{path, probability, pfs_months}],
                "intervention_windows": List[{start, end, priority}],
                "confidence": float
            }
        """
        logger.info(f"ðŸ”® Predicting trajectories for {self.patient_id}")
        
        self.state = TwinState.PREDICTING
        
        # Temporal analysis
        progression = self.temporal_analyzer.analyze_disease_progression(self.patient_id)
        
        # Find similar patients
        similar_patients = []
        if self.graph_db.is_available:
            try:
                similar_patients = self.graph_db.find_similar_patients(
                    stage=self.patient_data.get("stage"),
                    ps_score=self.patient_data.get("performance_status", 1)
                )
            except Exception as e:
                logger.warning(f"âš  Similar patient search failed: {e}")
        
        # Placeholder predictions (would use trajectory predictor agent)
        predictions = {
            "pathways": [
                {
                    "path": "stable_current_therapy",
                    "description": "Continue current therapy - stable disease",
                    "probability": 0.58,
                    "median_pfs_months": 8.3,
                    "supporting_cases": len(similar_patients)
                }
            ],
            "intervention_windows": [],
            "confidence": 0.75 if len(similar_patients) >= 10 else 0.50,
            "similar_patients_analyzed": len(similar_patients),
            "temporal_data_points": len(progression.get("timeline", []))
        }
        
        self.prediction_cache = predictions
        self.state = TwinState.ACTIVE
        
        return predictions
        
    def get_current_state(self) -> Dict[str, Any]:
        """
        Get current state of the digital twin
        
        Returns:
            Complete twin state including clinical data, predictions, alerts
        """
        return {
            "twin_id": self.twin_id,
            "patient_id": self.patient_id,
            "state": self.state.value,
            "created_at": self.created_at.isoformat(),
            "last_updated": self.last_updated.isoformat(),
            "clinical_state": self.patient_data,
            "active_alerts": [
                {
                    "alert_id": alert.alert_id,
                    "severity": alert.severity,
                    "category": alert.category,
                    "message": alert.message,
                    "timestamp": alert.timestamp.isoformat(),
                    "confidence": alert.confidence
                }
                for alert in self.active_alerts
            ],
            "predictions": self.prediction_cache,
            "context_graph": {
                "nodes": len(self.context_graph.nodes),
                "edges": len(self.context_graph.edges),
                "layers": self._analyze_graph_layers()
            },
            "snapshots_count": len(self.snapshots)
        }
        
    def get_reasoning_chain(self, recommendation_id: str) -> List[Dict[str, Any]]:
        """
        Get complete reasoning chain for a recommendation
        
        Shows audit trail: data â†’ agents â†’ reasoning â†’ recommendation
        
        Args:
            recommendation_id: ID of recommendation node
            
        Returns:
            List of nodes in reasoning chain with timestamps
        """
        chain = self.context_graph.get_reasoning_chain(recommendation_id)
        
        return [
            {
                "node_id": node.node_id,
                "type": node.node_type,
                "content": node.content,
                "timestamp": node.timestamp.isoformat(),
                "source_agent": node.source_agent,
                "confidence": node.confidence
            }
            for node in chain
        ]
        
    def export_twin(self) -> Dict[str, Any]:
        """
        Export complete digital twin state for backup or transfer
        
        Returns:
            Serializable representation of entire twin
        """
        return {
            "twin_metadata": {
                "twin_id": self.twin_id,
                "patient_id": self.patient_id,
                "created_at": self.created_at.isoformat(),
                "last_updated": self.last_updated.isoformat(),
                "state": self.state.value
            },
            "patient_data": self.patient_data,
            "context_graph": self.context_graph.to_dict(),
            "active_alerts": [
                {
                    "alert_id": alert.alert_id,
                    "severity": alert.severity,
                    "category": alert.category,
                    "message": alert.message,
                    "timestamp": alert.timestamp.isoformat()
                }
                for alert in self.active_alerts
            ],
            "predictions": self.prediction_cache,
            "snapshots": [
                {
                    "snapshot_id": s.snapshot_id,
                    "timestamp": s.timestamp.isoformat(),
                    "clinical_state": s.clinical_state,
                    "predictions": s.predictions
                }
                for s in self.snapshots
            ]
        }
        
    # ========================================
    # PRIVATE HELPER METHODS
    # ========================================
    
    def _detect_changes(self, update_type: str, data: Dict[str, Any]) -> List[str]:
        """Detect what changed in the update"""
        changes = []
        
        if update_type == UpdateType.LAB_RESULT.value:
            changes.append("new_lab_data")
            # Check for significant changes in biomarkers
            if "mutation" in str(data).lower() or "biomarker" in str(data).lower():
                changes.append("biomarker_change")
                
        elif update_type == UpdateType.IMAGING.value:
            changes.append("new_imaging")
            # Check for progression
            if "progression" in str(data).lower() or "increase" in str(data).lower():
                changes.append("possible_progression")
                
        elif update_type == UpdateType.PROGRESSION_EVENT.value:
            changes.append("confirmed_progression")
            
        elif update_type == UpdateType.TREATMENT_CHANGE.value:
            changes.append("treatment_modified")
            
        return changes
        
    def _identify_affected_agents(self, update_type: str, 
                                  changes: List[str]) -> List[str]:
        """Identify which agents need to re-run based on changes"""
        affected = []
        
        if "biomarker_change" in changes or update_type == UpdateType.LAB_RESULT.value:
            affected.append("biomarker")
            
        if "possible_progression" in changes or "confirmed_progression" in changes:
            affected.extend(["nsclc", "sclc"])
            
        if "treatment_modified" in changes:
            affected.append("comorbidity")
            
        return list(set(affected))  # Remove duplicates
        
    def _should_update_predictions(self, update_type: str, 
                                   changes: List[str]) -> bool:
        """Determine if predictions need updating"""
        significant_changes = [
            "biomarker_change",
            "confirmed_progression",
            "treatment_modified"
        ]
        
        return any(change in changes for change in significant_changes)
        
    def _generate_alerts(self, update_type: str, changes: List[str],
                        agent_results: Dict[str, Any],
                        predictions: Dict[str, Any]) -> List[TwinAlert]:
        """Generate alerts based on updates and analysis"""
        alerts = []
        
        # Progression alert
        if "confirmed_progression" in changes:
            alerts.append(TwinAlert(
                alert_id=f"alert_{uuid.uuid4().hex[:8]}",
                severity="high",
                category="progression",
                message="Disease progression detected - consider treatment modification",
                timestamp=datetime.now(),
                triggering_event=update_type,
                recommended_actions=[
                    "Review imaging results",
                    "Discuss treatment options at MDT",
                    "Consider clinical trial eligibility"
                ],
                confidence=0.85,
                requires_human_review=True
            ))
            
        # Biomarker alert
        if "biomarker_change" in changes:
            biomarker_result = agent_results.get("biomarker", {})
            if biomarker_result.get("resistance_mutations"):
                alerts.append(TwinAlert(
                    alert_id=f"alert_{uuid.uuid4().hex[:8]}",
                    severity="high",
                    category="biomarker",
                    message="Resistance mutation detected",
                    timestamp=datetime.now(),
                    triggering_event=update_type,
                    recommended_actions=[
                        "Consider next-line targeted therapy",
                        "Review alternative treatment options"
                    ],
                    confidence=biomarker_result.get("confidence", 0.75),
                    requires_human_review=True
                ))
                
        return alerts
        
    def _create_snapshot(self, clinical_state: Dict[str, Any],
                        predictions: Dict[str, Any],
                        alerts: List[TwinAlert]) -> TwinSnapshot:
        """Create point-in-time snapshot"""
        return TwinSnapshot(
            snapshot_id=f"snapshot_{uuid.uuid4().hex[:8]}",
            patient_id=self.patient_id,
            timestamp=datetime.now(),
            clinical_state=clinical_state,
            predictions=predictions,
            active_alerts=alerts,
            confidence_scores={
                "overall": predictions.get("confidence", 0.0)
            },
            context_graph_summary={
                "nodes": len(self.context_graph.nodes),
                "edges": len(self.context_graph.edges)
            }
        )
        
    def _analyze_graph_layers(self) -> Dict[str, int]:
        """Analyze context graph structure by layer"""
        layers = {
            "clinical_facts": 0,
            "temporal_events": 0,
            "reasoning": 0,
            "predictions": 0
        }
        
        for node in self.context_graph.nodes.values():
            if node.node_type in ["patient", "diagnosis", "lab_result", "treatment"]:
                layers["clinical_facts"] += 1
            elif node.node_type in ["event", "progression"]:
                layers["temporal_events"] += 1
            elif node.node_type in ["agent_output", "inference"]:
                layers["reasoning"] += 1
            elif node.node_type in ["prediction", "risk_assessment", "recommendation"]:
                layers["predictions"] += 1
                
        return layers


# ========================================
# CONVENIENCE FUNCTIONS
# ========================================

async def create_digital_twin(patient_id: str, 
                             patient_data: Dict[str, Any]) -> DigitalTwinEngine:
    """
    Convenience function to create and initialize a digital twin
    
    Example:
        twin = await create_digital_twin("P12345", {
            "age": 68,
            "stage": "IIIA",
            "histology": "Adenocarcinoma",
            "biomarkers": {"EGFR": "Ex19del"}
        })
    """
    engine = DigitalTwinEngine(patient_id=patient_id)
    await engine.initialize(patient_data)
    return engine


async def demo_digital_twin():
    """Demo usage of Digital Twin Engine"""
    print("ðŸš€ Digital Twin Engine Demo\n")
    
    # Create patient data
    patient_data = {
        "patient_id": "P12345",
        "age": 68,
        "gender": "M",
        "stage": "IIIA",
        "histology": "Adenocarcinoma",
        "cancer_type": "NSCLC",
        "performance_status": 1,
        "biomarkers": {
            "EGFR": "Ex19del positive"
        }
    }
    
    # Initialize twin
    twin = DigitalTwinEngine(patient_id="P12345")
    init_result = await twin.initialize(patient_data)
    
    print(f"âœ… Twin initialized: {init_result['twin_id']}")
    print(f"   Context graph: {init_result['context_graph_nodes']} nodes\n")
    
    # Simulate lab result update
    print("ðŸ”¬ New lab result: T790M resistance mutation detected\n")
    update_result = await twin.update({
        "type": UpdateType.LAB_RESULT.value,
        "data": {
            "test": "EGFR mutation analysis",
            "result": "T790M detected",
            "allele_frequency": 0.15
        }
    })
    
    print(f"   Alerts generated: {len(update_result['new_alerts'])}")
    for alert in update_result['new_alerts']:
        print(f"   âš  {alert['severity'].upper()}: {alert['message']}")
    
    print(f"\n   Agents re-run: {', '.join(update_result['affected_agents'])}\n")
    
    # Get predictions
    print("ðŸ”® Generating trajectory predictions...\n")
    predictions = await twin.predict_trajectories()
    
    print(f"   Predicted pathways: {len(predictions['pathways'])}")
    for pathway in predictions['pathways']:
        print(f"   â€¢ {pathway['description']}")
        print(f"     Probability: {pathway['probability']:.0%}, PFS: {pathway['median_pfs_months']} months\n")
    
    # Get current state
    state = twin.get_current_state()
    print(f"ðŸ“Š Current Twin State:")
    print(f"   State: {state['state']}")
    print(f"   Active alerts: {len(state['active_alerts'])}")
    print(f"   Context graph: {state['context_graph']['nodes']} nodes")
    print(f"   Snapshots: {state['snapshots_count']}\n")
    
    # Export twin
    export = twin.export_twin()
    print(f"ðŸ’¾ Twin exported: {len(export['context_graph']['nodes'])} nodes in graph\n")
    
    print("âœ… Demo complete!")


if __name__ == "__main__":
    asyncio.run(demo_digital_twin())
