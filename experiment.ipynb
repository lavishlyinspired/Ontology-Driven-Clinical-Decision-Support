{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ontology-Driven Clinical Decision Support - End-to-End Experiments\n",
    "\n",
    "This notebook provides a comprehensive end-to-end experimentation pipeline for the Lung Cancer Assistant (LCA) system.\n",
    "\n",
    "## Experiments Covered\n",
    "\n",
    "1. **Environment Setup & Validation**\n",
    "2. **Ontology Construction & Inspection** (LUCADA + SNOMED-CT)\n",
    "3. **Guideline Rules Engine** (NICE CG121)\n",
    "4. **Individual Agent Testing** (all 6 core agents)\n",
    "5. **Full 6-Agent Workflow** (LangGraph pipeline)\n",
    "6. **Specialized Agents** (Biomarker, NSCLC, Comorbidity)\n",
    "7. **Multi-Patient Cohort Processing**\n",
    "8. **Synthetic Data Generation & Batch Analysis**\n",
    "9. **Analytics** (Survival, Uncertainty, Counterfactual)\n",
    "10. **Visualization & Reporting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Environment Setup & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Ensure project root is on the path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '.'))\n",
    "if PROJECT_ROOT not in sys.path:\n",
    "    sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Python version: {sys.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate core dependencies\n",
    "dependencies = {\n",
    "    'pydantic': 'pydantic',\n",
    "    'owlready2': 'owlready2',\n",
    "    'rdflib': 'rdflib',\n",
    "    'numpy': 'numpy',\n",
    "    'pandas': 'pandas',\n",
    "    'matplotlib': 'matplotlib',\n",
    "    'seaborn': 'seaborn',\n",
    "}\n",
    "\n",
    "optional_deps = {\n",
    "    'langchain': 'langchain',\n",
    "    'langgraph': 'langgraph',\n",
    "    'neo4j': 'neo4j',\n",
    "    'lifelines': 'lifelines',\n",
    "    'sentence_transformers': 'sentence-transformers',\n",
    "}\n",
    "\n",
    "print(\"=== Core Dependencies ===\")\n",
    "for name, pkg in dependencies.items():\n",
    "    try:\n",
    "        mod = __import__(name)\n",
    "        ver = getattr(mod, '__version__', 'installed')\n",
    "        print(f\"  [OK] {pkg}: {ver}\")\n",
    "    except ImportError:\n",
    "        print(f\"  [MISSING] {pkg} - install with: pip install {pkg}\")\n",
    "\n",
    "print(\"\\n=== Optional Dependencies ===\")\n",
    "for name, pkg in optional_deps.items():\n",
    "    try:\n",
    "        mod = __import__(name)\n",
    "        ver = getattr(mod, '__version__', 'installed')\n",
    "        print(f\"  [OK] {pkg}: {ver}\")\n",
    "    except ImportError:\n",
    "        print(f\"  [SKIP] {pkg} - not installed (some experiments will use fallbacks)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports used throughout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pprint import pprint\n",
    "\n",
    "# Plotting config\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "sns.set_theme(style='whitegrid')\n",
    "\n",
    "print(\"Common imports loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Ontology Construction & Inspection\n",
    "\n",
    "Build the LUCADA OWL 2 ontology and inspect its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.ontology.lucada_ontology import LUCADAOntology\n",
    "from backend.src.ontology.snomed_loader import SNOMEDLoader\n",
    "\n",
    "# Create the ontology\n",
    "lucada = LUCADAOntology()\n",
    "onto = lucada.create()\n",
    "\n",
    "print(f\"Ontology IRI: {onto.base_iri}\")\n",
    "print(f\"Number of classes: {len(list(onto.classes()))}\")\n",
    "print(f\"Number of object properties: {len(list(onto.object_properties()))}\")\n",
    "print(f\"Number of data properties: {len(list(onto.data_properties()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all ontology classes grouped by hierarchy\n",
    "print(\"=== LUCADA Ontology Classes ===\")\n",
    "for cls in sorted(onto.classes(), key=lambda c: c.name):\n",
    "    parents = [p.name for p in cls.is_a if hasattr(p, 'name')]\n",
    "    print(f\"  {cls.name} -> subclass of: {parents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect SNOMED-CT mappings\n",
    "snomed = SNOMEDLoader()\n",
    "print(\"=== SNOMED-CT Lung Cancer Codes ===\")\n",
    "for concept_name, code in sorted(snomed.LUNG_CANCER_CODES.items()):\n",
    "    print(f\"  {concept_name}: {code}\")\n",
    "\n",
    "print(f\"\\nTotal SNOMED codes available: {len(snomed.LUNG_CANCER_CODES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize ontology class hierarchy\n",
    "class_names = [cls.name for cls in onto.classes()]\n",
    "parent_counts = {}\n",
    "for cls in onto.classes():\n",
    "    for parent in cls.is_a:\n",
    "        if hasattr(parent, 'name'):\n",
    "            parent_counts[parent.name] = parent_counts.get(parent.name, 0) + 1\n",
    "\n",
    "if parent_counts:\n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    top_parents = dict(sorted(parent_counts.items(), key=lambda x: x[1], reverse=True)[:15])\n",
    "    ax.barh(list(top_parents.keys()), list(top_parents.values()), color='steelblue')\n",
    "    ax.set_xlabel('Number of Subclasses')\n",
    "    ax.set_title('LUCADA Ontology - Top Parent Classes by Subclass Count')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No parent hierarchy data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Guideline Rules Engine (NICE CG121)\n",
    "\n",
    "Test the clinical guideline rules that drive treatment recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.ontology.guideline_rules import GuidelineRuleEngine, GuidelineRule\n",
    "\n",
    "rule_engine = GuidelineRuleEngine()\n",
    "\n",
    "print(\"=== NICE Lung Cancer Guideline Rules ===\")\n",
    "print(f\"Total rules loaded: {len(rule_engine.NICE_GUIDELINES)}\\n\")\n",
    "\n",
    "for rule in rule_engine.NICE_GUIDELINES:\n",
    "    print(f\"Rule {rule.rule_id}: {rule.name}\")\n",
    "    print(f\"  Source: {rule.source}\")\n",
    "    print(f\"  Treatment: {rule.recommended_treatment}\")\n",
    "    print(f\"  Intent: {rule.treatment_intent}\")\n",
    "    print(f\"  Evidence: {rule.evidence_level}\")\n",
    "    print(f\"  Description: {rule.description[:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize guideline rule distribution\n",
    "rules_df = pd.DataFrame([\n",
    "    {\n",
    "        'rule_id': r.rule_id,\n",
    "        'treatment': r.recommended_treatment,\n",
    "        'intent': r.treatment_intent,\n",
    "        'evidence': r.evidence_level\n",
    "    }\n",
    "    for r in rule_engine.NICE_GUIDELINES\n",
    "])\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "\n",
    "# Treatment types\n",
    "rules_df['treatment'].value_counts().plot(kind='bar', ax=axes[0], color='teal')\n",
    "axes[0].set_title('Rules by Treatment Type')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Treatment intent\n",
    "rules_df['intent'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.0f%%')\n",
    "axes[1].set_title('Rules by Treatment Intent')\n",
    "\n",
    "# Evidence level\n",
    "rules_df['evidence'].value_counts().plot(kind='bar', ax=axes[2], color='coral')\n",
    "axes[2].set_title('Rules by Evidence Level')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.suptitle('NICE CG121 Guideline Rules Distribution', fontsize=14, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Individual Agent Testing\n",
    "\n",
    "Test each of the 6 core agents independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test patients\n",
    "test_patients = [\n",
    "    {\n",
    "        \"name\": \"Jenny_Sesen\",\n",
    "        \"sex\": \"F\",\n",
    "        \"age\": 72,\n",
    "        \"tnm_stage\": \"IIA\",\n",
    "        \"histology_type\": \"Carcinosarcoma\",\n",
    "        \"performance_status\": 1,\n",
    "        \"fev1_percent\": 75.0,\n",
    "        \"laterality\": \"Right\",\n",
    "        \"comorbidities\": [],\n",
    "        \"notes\": \"Canonical example from Sesen et al. paper\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"John_Smith\",\n",
    "        \"sex\": \"M\",\n",
    "        \"age\": 65,\n",
    "        \"tnm_stage\": \"IB\",\n",
    "        \"histology_type\": \"Adenocarcinoma\",\n",
    "        \"performance_status\": 0,\n",
    "        \"fev1_percent\": 85.0,\n",
    "        \"laterality\": \"Left\",\n",
    "        \"comorbidities\": [],\n",
    "        \"notes\": \"Early stage NSCLC, ideal surgery candidate\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Mary_Williams\",\n",
    "        \"sex\": \"F\",\n",
    "        \"age\": 58,\n",
    "        \"tnm_stage\": \"IIIA\",\n",
    "        \"histology_type\": \"SquamousCellCarcinoma\",\n",
    "        \"performance_status\": 1,\n",
    "        \"fev1_percent\": 70.0,\n",
    "        \"laterality\": \"Right\",\n",
    "        \"comorbidities\": [\"COPD\"],\n",
    "        \"notes\": \"Locally advanced NSCLC with COPD\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Robert_Johnson\",\n",
    "        \"sex\": \"M\",\n",
    "        \"age\": 68,\n",
    "        \"tnm_stage\": \"IV\",\n",
    "        \"histology_type\": \"Adenocarcinoma\",\n",
    "        \"performance_status\": 1,\n",
    "        \"fev1_percent\": None,\n",
    "        \"laterality\": \"Right\",\n",
    "        \"comorbidities\": [\"Hypertension\"],\n",
    "        \"notes\": \"Metastatic NSCLC\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Sarah_Davis\",\n",
    "        \"sex\": \"F\",\n",
    "        \"age\": 62,\n",
    "        \"tnm_stage\": \"IIIB\",\n",
    "        \"histology_type\": \"SmallCellCarcinoma\",\n",
    "        \"performance_status\": 2,\n",
    "        \"fev1_percent\": 55.0,\n",
    "        \"laterality\": \"Left\",\n",
    "        \"comorbidities\": [\"COPD\", \"Diabetes\"],\n",
    "        \"notes\": \"SCLC with multiple comorbidities\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Defined {len(test_patients)} test patients.\")\n",
    "for p in test_patients:\n",
    "    print(f\"  - {p['name']}: {p['histology_type']}, Stage {p['tnm_stage']}, PS {p['performance_status']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Agent 1: Ingestion Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.ingestion_agent import IngestionAgent\n",
    "\n",
    "ingestion_agent = IngestionAgent()\n",
    "\n",
    "print(\"=== Ingestion Agent Results ===\")\n",
    "ingested_patients = []\n",
    "for patient_data in test_patients:\n",
    "    patient_fact, errors = ingestion_agent.execute(patient_data)\n",
    "    if patient_fact:\n",
    "        ingested_patients.append(patient_fact)\n",
    "        print(f\"\\n[OK] {patient_fact.name}\")\n",
    "        print(f\"  Patient ID: {patient_fact.patient_id}\")\n",
    "        print(f\"  Stage: {patient_fact.tnm_stage}, Histology: {patient_fact.histology_type}\")\n",
    "        print(f\"  PS: {patient_fact.performance_status}, FEV1: {patient_fact.fev1_percent}\")\n",
    "    else:\n",
    "        print(f\"\\n[ERROR] {patient_data['name']}: {errors}\")\n",
    "\n",
    "print(f\"\\nSuccessfully ingested: {len(ingested_patients)}/{len(test_patients)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test edge cases for ingestion\n",
    "edge_cases = [\n",
    "    {\"name\": \"Invalid_Stage\", \"sex\": \"M\", \"age\": 50, \"tnm_stage\": \"Stage IIIA\",\n",
    "     \"histology_type\": \"adenocarcinoma\", \"performance_status\": 1},\n",
    "    {\"name\": \"Missing_Fields\", \"sex\": \"F\", \"age\": 45},\n",
    "    {\"name\": \"Extreme_Age\", \"sex\": \"M\", \"age\": 95, \"tnm_stage\": \"IV\",\n",
    "     \"histology_type\": \"SmallCellCarcinoma\", \"performance_status\": 3},\n",
    "]\n",
    "\n",
    "print(\"=== Edge Case Testing ===\")\n",
    "for case in edge_cases:\n",
    "    patient_fact, errors = ingestion_agent.execute(case)\n",
    "    status = \"OK\" if patient_fact else \"REJECTED\"\n",
    "    print(f\"  [{status}] {case['name']}: errors={errors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Agent 2: Semantic Mapping Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.semantic_mapping_agent import SemanticMappingAgent\n",
    "\n",
    "semantic_agent = SemanticMappingAgent()\n",
    "\n",
    "print(\"=== Semantic Mapping Results ===\")\n",
    "mapped_patients = []\n",
    "for patient_fact in ingested_patients:\n",
    "    patient_with_codes, confidence = semantic_agent.execute(patient_fact)\n",
    "    mapped_patients.append(patient_with_codes)\n",
    "    print(f\"\\n{patient_fact.name} (confidence: {confidence:.2f})\")\n",
    "    print(f\"  SNOMED Diagnosis: {patient_with_codes.snomed_diagnosis_code}\")\n",
    "    print(f\"  SNOMED Histology: {patient_with_codes.snomed_histology_code}\")\n",
    "    print(f\"  SNOMED Stage: {patient_with_codes.snomed_stage_code}\")\n",
    "    print(f\"  SNOMED PS: {patient_with_codes.snomed_ps_code}\")\n",
    "    print(f\"  SNOMED Laterality: {patient_with_codes.snomed_laterality_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Agent 3: Classification Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.classification_agent import ClassificationAgent\n",
    "\n",
    "classification_agent = ClassificationAgent()\n",
    "\n",
    "print(\"=== Classification Results ===\")\n",
    "classifications = []\n",
    "for patient in mapped_patients:\n",
    "    result = classification_agent.execute(patient)\n",
    "    classifications.append(result)\n",
    "    print(f\"\\n{patient.name}:\")\n",
    "    print(f\"  Scenario: {result.scenario}\")\n",
    "    print(f\"  Confidence: {result.scenario_confidence:.2f}\")\n",
    "    print(f\"  Reasoning: {result.reasoning_chain[:3]}\")\n",
    "    print(f\"  Guidelines matched: {result.guideline_refs}\")\n",
    "    print(f\"  Recommendations:\")\n",
    "    for rec in result.recommendations[:3]:\n",
    "        print(f\"    - {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Agent 4: Conflict Resolution Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.conflict_resolution_agent import ConflictResolutionAgent\n",
    "\n",
    "conflict_agent = ConflictResolutionAgent()\n",
    "\n",
    "print(\"=== Conflict Resolution Results ===\")\n",
    "resolved_classifications = []\n",
    "all_conflict_reports = []\n",
    "for i, classification in enumerate(classifications):\n",
    "    resolved, conflicts = conflict_agent.execute(classification)\n",
    "    resolved_classifications.append(resolved)\n",
    "    all_conflict_reports.append(conflicts)\n",
    "    print(f\"\\n{mapped_patients[i].name}:\")\n",
    "    print(f\"  Conflicts found: {len(conflicts)}\")\n",
    "    for c in conflicts:\n",
    "        print(f\"    - Type: {c.conflict_type}, Resolution: {c.resolution}\")\n",
    "    print(f\"  Resolved scenario: {resolved.scenario}\")\n",
    "    print(f\"  Final recommendations: {len(resolved.recommendations)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Agent 6: Explanation Agent\n",
    "\n",
    "Note: The ExplanationAgent generates MDT summaries. If Ollama is not available, it falls back to template-based generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.explanation_agent import ExplanationAgent\n",
    "\n",
    "explanation_agent = ExplanationAgent()\n",
    "\n",
    "print(\"=== MDT Summary Generation ===\")\n",
    "mdt_summaries = []\n",
    "for i, (patient, classification) in enumerate(zip(mapped_patients, resolved_classifications)):\n",
    "    try:\n",
    "        summary = explanation_agent.execute(\n",
    "            patient_fact=patient,\n",
    "            classification=classification\n",
    "        )\n",
    "        mdt_summaries.append(summary)\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"MDT Summary for {patient.name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Clinical Summary: {summary.clinical_summary[:200]}...\")\n",
    "        print(f\"Scenario: {summary.classification_scenario}\")\n",
    "        print(f\"Confidence: {summary.scenario_confidence:.2f}\")\n",
    "        print(f\"Key Considerations: {summary.key_considerations[:3]}\")\n",
    "        print(f\"Discussion Points: {summary.discussion_points[:3]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n[WARN] {patient.name}: Explanation generation failed - {e}\")\n",
    "        mdt_summaries.append(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Full 6-Agent Workflow (LangGraph Pipeline)\n",
    "\n",
    "Run the complete end-to-end workflow through all 6 agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.lca_workflow import LCAWorkflow\n",
    "\n",
    "# Initialize workflow without Neo4j persistence (for standalone testing)\n",
    "workflow = LCAWorkflow(persist_results=False)\n",
    "\n",
    "print(\"=== Full 6-Agent Workflow Execution ===\")\n",
    "workflow_results = []\n",
    "\n",
    "for patient_data in test_patients:\n",
    "    print(f\"\\nProcessing: {patient_data['name']}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        result = workflow.run(patient_data)\n",
    "        elapsed = time.time() - start_time\n",
    "        workflow_results.append({\n",
    "            'name': patient_data['name'],\n",
    "            'result': result,\n",
    "            'time_seconds': elapsed,\n",
    "            'success': True\n",
    "        })\n",
    "        \n",
    "        print(f\"  Status: {result.get('workflow_status', 'unknown')}\")\n",
    "        print(f\"  Agent Chain: {result.get('agent_chain', [])}\")\n",
    "        print(f\"  Time: {elapsed:.2f}s\")\n",
    "        \n",
    "        if result.get('classification'):\n",
    "            cls = result['classification']\n",
    "            scenario = cls.scenario if hasattr(cls, 'scenario') else str(cls)\n",
    "            print(f\"  Scenario: {scenario}\")\n",
    "        \n",
    "        if result.get('mdt_summary'):\n",
    "            summary = result['mdt_summary']\n",
    "            text = summary.clinical_summary if hasattr(summary, 'clinical_summary') else str(summary)\n",
    "            print(f\"  MDT Summary: {text[:150]}...\")\n",
    "    except Exception as e:\n",
    "        elapsed = time.time() - start_time\n",
    "        workflow_results.append({\n",
    "            'name': patient_data['name'],\n",
    "            'result': None,\n",
    "            'time_seconds': elapsed,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        })\n",
    "        print(f\"  [ERROR] {e}\")\n",
    "\n",
    "# Summary\n",
    "successes = sum(1 for r in workflow_results if r['success'])\n",
    "print(f\"\\n=== Workflow Summary ===\")\n",
    "print(f\"Total: {len(workflow_results)}, Success: {successes}, Failed: {len(workflow_results) - successes}\")\n",
    "print(f\"Avg time: {np.mean([r['time_seconds'] for r in workflow_results]):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize workflow execution times\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "names = [r['name'] for r in workflow_results]\n",
    "times = [r['time_seconds'] for r in workflow_results]\n",
    "colors = ['green' if r['success'] else 'red' for r in workflow_results]\n",
    "\n",
    "ax.barh(names, times, color=colors)\n",
    "ax.set_xlabel('Execution Time (seconds)')\n",
    "ax.set_title('6-Agent Workflow Execution Time per Patient')\n",
    "for i, v in enumerate(times):\n",
    "    ax.text(v + 0.01, i, f'{v:.2f}s', va='center')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Specialized Agents\n",
    "\n",
    "Test the domain-specific specialized agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.biomarker_agent import BiomarkerAgent, BiomarkerProfile\n",
    "\n",
    "biomarker_agent = BiomarkerAgent()\n",
    "\n",
    "# Test with different biomarker profiles\n",
    "biomarker_profiles = [\n",
    "    BiomarkerProfile(egfr_mutation=\"positive\", egfr_mutation_type=\"Ex19del\", pdl1_tps=80.0),\n",
    "    BiomarkerProfile(alk_rearrangement=\"positive\", pdl1_tps=30.0),\n",
    "    BiomarkerProfile(pdl1_tps=90.0, tmb_score=15.0),\n",
    "    BiomarkerProfile(braf_mutation=\"positive\"),\n",
    "    BiomarkerProfile(),  # No actionable mutations\n",
    "]\n",
    "\n",
    "print(\"=== Biomarker Agent Results ===\")\n",
    "# Use the advanced NSCLC patient for biomarker testing\n",
    "if len(mapped_patients) >= 4:\n",
    "    test_patient = mapped_patients[3]  # Robert_Johnson, Stage IV Adenocarcinoma\n",
    "    for i, profile in enumerate(biomarker_profiles):\n",
    "        proposal = biomarker_agent.execute(test_patient, biomarker_profile=profile)\n",
    "        print(f\"\\nProfile {i+1}: {profile}\")\n",
    "        print(f\"  Treatment: {proposal.treatment}\")\n",
    "        print(f\"  Confidence: {proposal.confidence:.2f}\")\n",
    "        print(f\"  Rationale: {proposal.rationale[:150]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.nsclc_agent import NSCLCAgent\n",
    "\n",
    "nsclc_agent = NSCLCAgent()\n",
    "\n",
    "print(\"=== NSCLC Agent - Stage-Specific Pathways ===\")\n",
    "for patient in mapped_patients:\n",
    "    # Skip SCLC patients\n",
    "    if patient.histology_type in ['SmallCellCarcinoma']:\n",
    "        continue\n",
    "    try:\n",
    "        proposal = nsclc_agent.execute(patient)\n",
    "        print(f\"\\n{patient.name} (Stage {patient.tnm_stage}, {patient.histology_type}):\")\n",
    "        print(f\"  Treatment: {proposal.treatment}\")\n",
    "        print(f\"  Confidence: {proposal.confidence:.2f}\")\n",
    "        print(f\"  Rationale: {proposal.rationale[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{patient.name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.agents.comorbidity_agent import ComorbidityAgent\n",
    "\n",
    "comorbidity_agent = ComorbidityAgent()\n",
    "\n",
    "print(\"=== Comorbidity Agent Results ===\")\n",
    "for patient in mapped_patients:\n",
    "    try:\n",
    "        proposal = comorbidity_agent.execute(patient)\n",
    "        print(f\"\\n{patient.name} (comorbidities: {patient.comorbidities}):\")\n",
    "        print(f\"  Risk Assessment: {proposal.treatment}\")\n",
    "        print(f\"  Confidence: {proposal.confidence:.2f}\")\n",
    "        print(f\"  Rationale: {proposal.rationale[:200]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n{patient.name}: Error - {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Multi-Patient Cohort Processing\n",
    "\n",
    "Process a larger cohort from the sample patients and analyze distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.sample_patients import SAMPLE_PATIENTS\n",
    "\n",
    "print(f\"Sample patients available: {len(SAMPLE_PATIENTS)}\")\n",
    "for p in SAMPLE_PATIENTS:\n",
    "    print(f\"  - {p['name']}: Stage {p['tnm_stage']}, {p['histology_type']}, PS {p['performance_status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process all sample patients through the ingestion + classification pipeline\n",
    "cohort_results = []\n",
    "\n",
    "for patient_data in SAMPLE_PATIENTS:\n",
    "    try:\n",
    "        # Ingestion\n",
    "        patient_fact, errors = ingestion_agent.execute(patient_data)\n",
    "        if not patient_fact:\n",
    "            continue\n",
    "        \n",
    "        # Semantic mapping\n",
    "        patient_with_codes, confidence = semantic_agent.execute(patient_fact)\n",
    "        \n",
    "        # Classification\n",
    "        classification = classification_agent.execute(patient_with_codes)\n",
    "        \n",
    "        cohort_results.append({\n",
    "            'name': patient_data['name'],\n",
    "            'stage': patient_data['tnm_stage'],\n",
    "            'histology': patient_data['histology_type'],\n",
    "            'ps': patient_data['performance_status'],\n",
    "            'age': patient_data['age'],\n",
    "            'scenario': classification.scenario,\n",
    "            'confidence': classification.scenario_confidence,\n",
    "            'num_recommendations': len(classification.recommendations),\n",
    "            'guidelines': classification.guideline_refs,\n",
    "            'mapping_confidence': confidence\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {patient_data.get('name', 'unknown')}: {e}\")\n",
    "\n",
    "cohort_df = pd.DataFrame(cohort_results)\n",
    "print(f\"\\nCohort processed: {len(cohort_df)} patients\")\n",
    "cohort_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cohort analysis visualizations\n",
    "if len(cohort_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Stage distribution\n",
    "    cohort_df['stage'].value_counts().plot(kind='bar', ax=axes[0, 0], color='steelblue')\n",
    "    axes[0, 0].set_title('Stage Distribution')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Histology distribution\n",
    "    cohort_df['histology'].value_counts().plot(kind='bar', ax=axes[0, 1], color='teal')\n",
    "    axes[0, 1].set_title('Histology Distribution')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Classification confidence\n",
    "    axes[1, 0].hist(cohort_df['confidence'], bins=10, color='coral', edgecolor='black')\n",
    "    axes[1, 0].set_title('Classification Confidence Distribution')\n",
    "    axes[1, 0].set_xlabel('Confidence')\n",
    "    \n",
    "    # Age vs Performance Status\n",
    "    scatter = axes[1, 1].scatter(\n",
    "        cohort_df['age'], cohort_df['ps'],\n",
    "        c=cohort_df['confidence'], cmap='RdYlGn', s=100, edgecolors='black'\n",
    "    )\n",
    "    axes[1, 1].set_xlabel('Age')\n",
    "    axes[1, 1].set_ylabel('Performance Status')\n",
    "    axes[1, 1].set_title('Age vs PS (color = confidence)')\n",
    "    plt.colorbar(scatter, ax=axes[1, 1], label='Confidence')\n",
    "    \n",
    "    plt.suptitle('Cohort Analysis', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No cohort data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Synthetic Data Generation & Batch Analysis\n",
    "\n",
    "Generate a larger synthetic cohort and run batch processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.synthetic_patient_generator import SyntheticPatientGenerator\n",
    "\n",
    "generator = SyntheticPatientGenerator()\n",
    "\n",
    "# Generate 50 synthetic patients\n",
    "N_SYNTHETIC = 50\n",
    "synthetic_patients = [generator.generate_patient() for _ in range(N_SYNTHETIC)]\n",
    "\n",
    "print(f\"Generated {len(synthetic_patients)} synthetic patients\")\n",
    "print(f\"\\nStage distribution:\")\n",
    "stage_counts = {}\n",
    "for p in synthetic_patients:\n",
    "    stage_counts[p.tnm_stage] = stage_counts.get(p.tnm_stage, 0) + 1\n",
    "for stage, count in sorted(stage_counts.items()):\n",
    "    print(f\"  {stage}: {count} ({count/len(synthetic_patients)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch process synthetic patients through the pipeline\n",
    "batch_results = []\n",
    "batch_errors = []\n",
    "\n",
    "print(f\"Processing {N_SYNTHETIC} synthetic patients...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for i, patient in enumerate(synthetic_patients):\n",
    "    try:\n",
    "        patient_data = patient.to_dict()\n",
    "        patient_data['name'] = patient.name  # ensure name field\n",
    "        \n",
    "        # Ingestion\n",
    "        patient_fact, errors = ingestion_agent.execute(patient_data)\n",
    "        if not patient_fact:\n",
    "            batch_errors.append({'patient': patient.name, 'stage': 'ingestion', 'error': str(errors)})\n",
    "            continue\n",
    "        \n",
    "        # Semantic mapping\n",
    "        patient_with_codes, confidence = semantic_agent.execute(patient_fact)\n",
    "        \n",
    "        # Classification\n",
    "        classification = classification_agent.execute(patient_with_codes)\n",
    "        \n",
    "        # Conflict resolution\n",
    "        resolved, conflicts = conflict_agent.execute(classification)\n",
    "        \n",
    "        batch_results.append({\n",
    "            'name': patient.name,\n",
    "            'age': patient.age_at_diagnosis,\n",
    "            'sex': patient.sex,\n",
    "            'stage': patient.tnm_stage,\n",
    "            'histology': patient.histology_type,\n",
    "            'ps': patient.performance_status,\n",
    "            'fev1': patient.fev1_percent,\n",
    "            'comorbidities': len(patient.comorbidities or []),\n",
    "            'scenario': resolved.scenario,\n",
    "            'confidence': resolved.scenario_confidence,\n",
    "            'num_recommendations': len(resolved.recommendations),\n",
    "            'num_conflicts': len(conflicts),\n",
    "            'mapping_confidence': confidence\n",
    "        })\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Processed {i+1}/{N_SYNTHETIC}...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        batch_errors.append({'patient': patient.name, 'stage': 'pipeline', 'error': str(e)})\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "batch_df = pd.DataFrame(batch_results)\n",
    "\n",
    "print(f\"\\n=== Batch Processing Complete ===\")\n",
    "print(f\"Total time: {total_time:.2f}s\")\n",
    "print(f\"Success: {len(batch_results)}, Errors: {len(batch_errors)}\")\n",
    "print(f\"Throughput: {len(batch_results)/total_time:.1f} patients/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive batch analysis\n",
    "if len(batch_df) > 0:\n",
    "    print(\"=== Batch Statistics ===\")\n",
    "    print(f\"\\nConfidence: mean={batch_df['confidence'].mean():.3f}, \"\n",
    "          f\"std={batch_df['confidence'].std():.3f}, \"\n",
    "          f\"min={batch_df['confidence'].min():.3f}, \"\n",
    "          f\"max={batch_df['confidence'].max():.3f}\")\n",
    "    print(f\"\\nMapping confidence: mean={batch_df['mapping_confidence'].mean():.3f}\")\n",
    "    print(f\"\\nRecommendations per patient: mean={batch_df['num_recommendations'].mean():.1f}\")\n",
    "    print(f\"Conflicts per patient: mean={batch_df['num_conflicts'].mean():.1f}\")\n",
    "    \n",
    "    print(f\"\\nScenario distribution:\")\n",
    "    for scenario, count in batch_df['scenario'].value_counts().items():\n",
    "        print(f\"  {scenario}: {count} ({count/len(batch_df)*100:.0f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch visualizations\n",
    "if len(batch_df) > 0:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    # 1. Stage vs Confidence\n",
    "    batch_df.boxplot(column='confidence', by='stage', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Classification Confidence by Stage')\n",
    "    axes[0, 0].set_xlabel('TNM Stage')\n",
    "    \n",
    "    # 2. Histology distribution\n",
    "    batch_df['histology'].value_counts().plot(kind='pie', ax=axes[0, 1], autopct='%1.0f%%')\n",
    "    axes[0, 1].set_title('Histology Distribution')\n",
    "    \n",
    "    # 3. Age distribution by stage\n",
    "    for stage in batch_df['stage'].unique():\n",
    "        subset = batch_df[batch_df['stage'] == stage]\n",
    "        axes[0, 2].hist(subset['age'], alpha=0.5, label=stage, bins=10)\n",
    "    axes[0, 2].set_title('Age Distribution by Stage')\n",
    "    axes[0, 2].set_xlabel('Age')\n",
    "    axes[0, 2].legend(fontsize=8)\n",
    "    \n",
    "    # 4. Recommendations heatmap: stage x histology\n",
    "    pivot = batch_df.pivot_table(\n",
    "        values='num_recommendations', index='stage', columns='histology', aggfunc='mean'\n",
    "    )\n",
    "    sns.heatmap(pivot, annot=True, fmt='.1f', cmap='YlOrRd', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Avg Recommendations (Stage x Histology)')\n",
    "    \n",
    "    # 5. Confidence vs number of comorbidities\n",
    "    axes[1, 1].scatter(batch_df['comorbidities'], batch_df['confidence'],\n",
    "                       c=batch_df['ps'], cmap='viridis', s=60, edgecolors='black')\n",
    "    axes[1, 1].set_xlabel('Number of Comorbidities')\n",
    "    axes[1, 1].set_ylabel('Classification Confidence')\n",
    "    axes[1, 1].set_title('Confidence vs Comorbidities (color=PS)')\n",
    "    \n",
    "    # 6. Performance status vs conflicts\n",
    "    batch_df.boxplot(column='num_conflicts', by='ps', ax=axes[1, 2])\n",
    "    axes[1, 2].set_title('Conflicts by Performance Status')\n",
    "    axes[1, 2].set_xlabel('Performance Status (WHO)')\n",
    "    \n",
    "    plt.suptitle(f'Synthetic Cohort Analysis (N={len(batch_df)})', fontsize=14, y=1.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Analytics Modules\n",
    "\n",
    "Test survival analysis, uncertainty quantification, and counterfactual reasoning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Survival Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.analytics.survival_analyzer import SurvivalAnalyzer\n",
    "\n",
    "survival_analyzer = SurvivalAnalyzer()\n",
    "\n",
    "# Generate synthetic survival data for demonstration\n",
    "np.random.seed(42)\n",
    "n_patients = 100\n",
    "\n",
    "survival_data = []\n",
    "for _ in range(n_patients):\n",
    "    stage = np.random.choice(['IA', 'IB', 'IIA', 'IIB', 'IIIA', 'IIIB', 'IV'],\n",
    "                             p=[0.10, 0.08, 0.12, 0.10, 0.15, 0.15, 0.30])\n",
    "    treatment = np.random.choice(['Surgery', 'Chemotherapy', 'Chemoradiotherapy', 'Immunotherapy'])\n",
    "    \n",
    "    # Simulate survival based on stage\n",
    "    base_survival = {'IA': 1800, 'IB': 1500, 'IIA': 1200, 'IIB': 1000,\n",
    "                     'IIIA': 700, 'IIIB': 500, 'IV': 300}\n",
    "    survival_days = max(30, int(np.random.exponential(base_survival[stage])))\n",
    "    event = 1 if np.random.random() < 0.7 else 0  # 70% observed events\n",
    "    \n",
    "    survival_data.append({\n",
    "        'patient_id': f'SYN-{_:03d}',\n",
    "        'stage': stage,\n",
    "        'treatment': treatment,\n",
    "        'survival_days': survival_days,\n",
    "        'event': event\n",
    "    })\n",
    "\n",
    "survival_df = pd.DataFrame(survival_data)\n",
    "print(f\"Survival dataset: {len(survival_df)} patients\")\n",
    "print(f\"\\nMedian survival by stage:\")\n",
    "print(survival_df.groupby('stage')['survival_days'].median().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaplan-Meier survival curves by stage\n",
    "try:\n",
    "    from lifelines import KaplanMeierFitter\n",
    "    from lifelines.statistics import logrank_test\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # By stage (grouped for clarity)\n",
    "    kmf = KaplanMeierFitter()\n",
    "    stage_groups = {'Early (I-II)': ['IA', 'IB', 'IIA', 'IIB'],\n",
    "                    'Locally Advanced (III)': ['IIIA', 'IIIB'],\n",
    "                    'Metastatic (IV)': ['IV']}\n",
    "    \n",
    "    for label, stages in stage_groups.items():\n",
    "        mask = survival_df['stage'].isin(stages)\n",
    "        kmf.fit(survival_df.loc[mask, 'survival_days'],\n",
    "                event_observed=survival_df.loc[mask, 'event'],\n",
    "                label=label)\n",
    "        kmf.plot_survival_function(ax=axes[0])\n",
    "    \n",
    "    axes[0].set_title('Kaplan-Meier Survival by Stage Group')\n",
    "    axes[0].set_xlabel('Days')\n",
    "    axes[0].set_ylabel('Survival Probability')\n",
    "    \n",
    "    # By treatment\n",
    "    for treatment in survival_df['treatment'].unique():\n",
    "        mask = survival_df['treatment'] == treatment\n",
    "        kmf.fit(survival_df.loc[mask, 'survival_days'],\n",
    "                event_observed=survival_df.loc[mask, 'event'],\n",
    "                label=treatment)\n",
    "        kmf.plot_survival_function(ax=axes[1])\n",
    "    \n",
    "    axes[1].set_title('Kaplan-Meier Survival by Treatment')\n",
    "    axes[1].set_xlabel('Days')\n",
    "    axes[1].set_ylabel('Survival Probability')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Log-rank test: early vs metastatic\n",
    "    early = survival_df[survival_df['stage'].isin(['IA', 'IB', 'IIA', 'IIB'])]\n",
    "    metastatic = survival_df[survival_df['stage'] == 'IV']\n",
    "    result = logrank_test(\n",
    "        early['survival_days'], metastatic['survival_days'],\n",
    "        event_observed_A=early['event'], event_observed_B=metastatic['event']\n",
    "    )\n",
    "    print(f\"Log-rank test (Early vs Metastatic): p={result.p_value:.4f}\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"lifelines not installed. Showing basic survival statistics instead.\")\n",
    "    print(survival_df.groupby('stage')['survival_days'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Uncertainty Quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.analytics.uncertainty_quantifier import UncertaintyQuantifier\n",
    "from backend.src.db.models import TreatmentRecommendation, EvidenceLevel, TreatmentIntent\n",
    "\n",
    "uq = UncertaintyQuantifier()\n",
    "\n",
    "print(\"=== Uncertainty Quantification ===\")\n",
    "\n",
    "# Create sample recommendations for uncertainty analysis\n",
    "sample_recommendations = [\n",
    "    TreatmentRecommendation(\n",
    "        patient_id=\"TEST-001\",\n",
    "        primary_treatment=\"Surgery (Lobectomy)\",\n",
    "        treatment_intent=TreatmentIntent.CURATIVE,\n",
    "        evidence_level=EvidenceLevel.GRADE_A,\n",
    "        confidence_score=0.92,\n",
    "        rationale=\"Early stage NSCLC with good PS - standard surgical approach\",\n",
    "        guideline_references=[\"NICE CG121 R2\"]\n",
    "    ),\n",
    "    TreatmentRecommendation(\n",
    "        patient_id=\"TEST-002\",\n",
    "        primary_treatment=\"Concurrent Chemoradiotherapy\",\n",
    "        treatment_intent=TreatmentIntent.CURATIVE,\n",
    "        evidence_level=EvidenceLevel.GRADE_B,\n",
    "        confidence_score=0.75,\n",
    "        rationale=\"Locally advanced NSCLC with comorbidities\",\n",
    "        guideline_references=[\"NICE CG121 R6\"]\n",
    "    ),\n",
    "    TreatmentRecommendation(\n",
    "        patient_id=\"TEST-003\",\n",
    "        primary_treatment=\"Palliative Chemotherapy\",\n",
    "        treatment_intent=TreatmentIntent.PALLIATIVE,\n",
    "        evidence_level=EvidenceLevel.GRADE_A,\n",
    "        confidence_score=0.85,\n",
    "        rationale=\"Metastatic NSCLC, PS 1\",\n",
    "        guideline_references=[\"NICE CG121 R1\"]\n",
    "    ),\n",
    "]\n",
    "\n",
    "uncertainty_results = []\n",
    "for i, (rec, patient) in enumerate(zip(sample_recommendations, ingested_patients[:3])):\n",
    "    try:\n",
    "        metrics = uq.quantify_recommendation_uncertainty(rec, patient)\n",
    "        uncertainty_results.append(metrics)\n",
    "        print(f\"\\n{patient.name} - {rec.primary_treatment}:\")\n",
    "        print(f\"  Confidence: {metrics.confidence_score:.3f}\")\n",
    "        print(f\"  Epistemic uncertainty: {metrics.epistemic_uncertainty:.3f}\")\n",
    "        print(f\"  Aleatoric uncertainty: {metrics.aleatoric_uncertainty:.3f}\")\n",
    "        print(f\"  Total uncertainty: {metrics.total_uncertainty:.3f}\")\n",
    "        print(f\"  Confidence level: {metrics.confidence_level}\")\n",
    "        print(f\"  Explanation: {metrics.explanation[:150]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError for {patient.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize uncertainty\n",
    "if uncertainty_results:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    names = [ingested_patients[i].name for i in range(len(uncertainty_results))]\n",
    "    epistemic = [m.epistemic_uncertainty for m in uncertainty_results]\n",
    "    aleatoric = [m.aleatoric_uncertainty for m in uncertainty_results]\n",
    "    \n",
    "    # Stacked bar: epistemic vs aleatoric\n",
    "    x = np.arange(len(names))\n",
    "    axes[0].bar(x, epistemic, label='Epistemic', color='steelblue')\n",
    "    axes[0].bar(x, aleatoric, bottom=epistemic, label='Aleatoric', color='coral')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(names, rotation=45)\n",
    "    axes[0].set_ylabel('Uncertainty')\n",
    "    axes[0].set_title('Uncertainty Decomposition')\n",
    "    axes[0].legend()\n",
    "    \n",
    "    # Confidence with error bars\n",
    "    confidences = [m.confidence_score for m in uncertainty_results]\n",
    "    totals = [m.total_uncertainty for m in uncertainty_results]\n",
    "    axes[1].bar(x, confidences, yerr=totals, capsize=5, color='teal', alpha=0.7)\n",
    "    axes[1].set_xticks(x)\n",
    "    axes[1].set_xticklabels(names, rotation=45)\n",
    "    axes[1].set_ylabel('Confidence Score')\n",
    "    axes[1].set_title('Recommendation Confidence with Uncertainty Bounds')\n",
    "    axes[1].set_ylim(0, 1.1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 Counterfactual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backend.src.analytics.counterfactual_engine import CounterfactualEngine\n",
    "\n",
    "cf_engine = CounterfactualEngine(workflow=workflow)\n",
    "\n",
    "print(\"=== Counterfactual Analysis ===\")\n",
    "print(\"What-if scenarios for treatment decision sensitivity\\n\")\n",
    "\n",
    "# Analyze counterfactuals for the canonical Jenny_Sesen case\n",
    "jenny_data = test_patients[0]\n",
    "\n",
    "try:\n",
    "    cf_result = cf_engine.analyze_counterfactuals(\n",
    "        patient_data=jenny_data,\n",
    "        attributes_to_vary=['tnm_stage', 'performance_status', 'fev1_percent']\n",
    "    )\n",
    "    \n",
    "    print(f\"Patient: {cf_result.patient_id}\")\n",
    "    print(f\"Original recommendation: {cf_result.original_recommendation}\")\n",
    "    print(f\"\\nCounterfactual scenarios:\")\n",
    "    for cf in cf_result.counterfactuals:\n",
    "        print(f\"  - {cf.get('description', cf)}\")\n",
    "    print(f\"\\nActionable interventions: {cf_result.actionable_interventions}\")\n",
    "    print(f\"Sensitivity: {cf_result.sensitivity_analysis}\")\n",
    "except Exception as e:\n",
    "    print(f\"Counterfactual analysis error: {e}\")\n",
    "    print(\"\\nRunning manual what-if analysis instead...\")\n",
    "    \n",
    "    # Manual what-if: vary stage\n",
    "    print(\"\\nWhat-if: Stage variation for Jenny_Sesen\")\n",
    "    stages = ['IA', 'IIA', 'IIIA', 'IV']\n",
    "    for stage in stages:\n",
    "        modified = jenny_data.copy()\n",
    "        modified['tnm_stage'] = stage\n",
    "        pf, _ = ingestion_agent.execute(modified)\n",
    "        if pf:\n",
    "            pwc, _ = semantic_agent.execute(pf)\n",
    "            cls = classification_agent.execute(pwc)\n",
    "            print(f\"  Stage {stage}: {cls.scenario} (confidence: {cls.scenario_confidence:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 10. Visualization & Reporting\n",
    "\n",
    "Generate final summary visualizations and a consolidated report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treatment recommendation decision matrix\n",
    "if len(batch_df) > 0:\n",
    "    # Cross-tabulation: stage x scenario\n",
    "    ct = pd.crosstab(batch_df['stage'], batch_df['scenario'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 6))\n",
    "    ct.plot(kind='bar', stacked=True, ax=ax, colormap='Set3')\n",
    "    ax.set_title('Treatment Scenarios by TNM Stage')\n",
    "    ax.set_xlabel('TNM Stage')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.legend(title='Scenario', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive performance summary\n",
    "print(\"=\" * 70)\n",
    "print(\"EXPERIMENT SUMMARY REPORT\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\\n--- Ontology ---\")\n",
    "print(f\"  Classes: {len(list(onto.classes()))}\")\n",
    "print(f\"  Object Properties: {len(list(onto.object_properties()))}\")\n",
    "print(f\"  Data Properties: {len(list(onto.data_properties()))}\")\n",
    "print(f\"  SNOMED Codes: {len(snomed.LUNG_CANCER_CODES)}\")\n",
    "print(f\"  Guideline Rules: {len(rule_engine.NICE_GUIDELINES)}\")\n",
    "\n",
    "print(f\"\\n--- Agent Pipeline ---\")\n",
    "print(f\"  Test patients processed: {len(test_patients)}\")\n",
    "print(f\"  Workflow executions: {len(workflow_results)}\")\n",
    "print(f\"  Workflow success rate: {successes}/{len(workflow_results)}\")\n",
    "if workflow_results:\n",
    "    print(f\"  Avg workflow time: {np.mean([r['time_seconds'] for r in workflow_results]):.2f}s\")\n",
    "\n",
    "print(f\"\\n--- Batch Processing ---\")\n",
    "print(f\"  Synthetic patients: {N_SYNTHETIC}\")\n",
    "print(f\"  Successfully processed: {len(batch_results)}\")\n",
    "print(f\"  Errors: {len(batch_errors)}\")\n",
    "if len(batch_df) > 0:\n",
    "    print(f\"  Mean confidence: {batch_df['confidence'].mean():.3f}\")\n",
    "    print(f\"  Mean mapping confidence: {batch_df['mapping_confidence'].mean():.3f}\")\n",
    "    print(f\"  Throughput: {len(batch_results)/total_time:.1f} patients/sec\")\n",
    "\n",
    "print(f\"\\n--- Analytics ---\")\n",
    "print(f\"  Survival dataset: {len(survival_df)} patients\")\n",
    "print(f\"  Uncertainty quantified: {len(uncertainty_results)} recommendations\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"All experiments completed.\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export results to CSV for external analysis\n",
    "if len(batch_df) > 0:\n",
    "    output_dir = os.path.join(PROJECT_ROOT, 'experiment_outputs')\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    batch_df.to_csv(os.path.join(output_dir, 'batch_results.csv'), index=False)\n",
    "    survival_df.to_csv(os.path.join(output_dir, 'survival_data.csv'), index=False)\n",
    "    \n",
    "    if len(cohort_df) > 0:\n",
    "        cohort_df.to_csv(os.path.join(output_dir, 'cohort_results.csv'), index=False)\n",
    "    \n",
    "    print(f\"Results exported to: {output_dir}/\")\n",
    "    print(f\"  - batch_results.csv ({len(batch_df)} rows)\")\n",
    "    print(f\"  - survival_data.csv ({len(survival_df)} rows)\")\n",
    "    if len(cohort_df) > 0:\n",
    "        print(f\"  - cohort_results.csv ({len(cohort_df)} rows)\")\n",
    "else:\n",
    "    print(\"No batch data to export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbformat_minor": 2,
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
